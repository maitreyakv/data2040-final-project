{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "ratsi_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "velvet-worthy"
      },
      "source": [
        "# External package imports\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import json"
      ],
      "id": "velvet-worthy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6LuhvOJt3R1"
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "id": "Q6LuhvOJt3R1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrFINVktK1fu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "BrFINVktK1fu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "figured-dividend"
      },
      "source": [
        "# Import the custom data loader\n",
        "from data_loader import create_data_loader\n",
        "\n",
        "# Import the VGG model creator\n",
        "from vgg_initializer import initialize_vgg, initialize_vgg_3d, initialize_vgg_lstm"
      ],
      "id": "figured-dividend",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "italic-winner"
      },
      "source": [
        "# Get a list of the training record files\n",
        "tfrecord_file = \"/content/drive/MyDrive/ratsi_data.tfrecord\"\n",
        "metadata_file = \"/content/drive/MyDrive/ratsi_data.metadata.json\""
      ],
      "id": "italic-winner",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EHgpFq1Q-F5"
      },
      "source": [
        "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.model.reset_states()"
      ],
      "id": "2EHgpFq1Q-F5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyZKXVtwMimL"
      },
      "source": [
        "def train_model(name, model, batch_size, seq_size=1, lr=1e-3):\n",
        "    print(name)\n",
        "\n",
        "    # Initialize training and validation datasets\n",
        "    dataset_train, dataset_valid = create_data_loader(\n",
        "        tfrecord_file,\n",
        "        metadata_file,\n",
        "        valid_size=0.5,\n",
        "        batch_size=batch_size,\n",
        "        n_channels=3,\n",
        "        seq_size=seq_size\n",
        "    )\n",
        "\n",
        "    with open(metadata_file, \"r\") as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        mode=\"max\",\n",
        "        patience=4,\n",
        "        verbose=0,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    reset_states = ResetStatesCallback()\n",
        "\n",
        "    history = model.fit(\n",
        "        x=dataset_train,\n",
        "        epochs=40,\n",
        "        validation_data=dataset_valid,\n",
        "        callbacks=[early_stop, reset_states]\n",
        "    )\n",
        "\n",
        "    fig, axs = plt.subplots(ncols=2, figsize=(10,3))\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    axs[0].plot(history.history[\"val_loss\"], color=\"tab:red\", label=\"Validation\")\n",
        "    axs[0].plot(history.history[\"loss\"], color=\"tab:blue\", label=\"Training\")\n",
        "    axs[0].legend()\n",
        "    axs[0].set_xlabel(\"Epoch\")\n",
        "    axs[0].set_ylabel(\"Loss\")\n",
        "\n",
        "    axs[1].plot(history.history[\"val_accuracy\"], color=\"tab:red\", label=\"Validation\")\n",
        "    axs[1].plot(history.history[\"accuracy\"], color=\"tab:blue\", label=\"Training\")\n",
        "    axs[1].legend()\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Accuracy\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    trainable_params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "    nontrainable_params = np.sum([np.prod(v.get_shape()) for v in model.non_trainable_weights])\n",
        "    total_params = trainable_params + nontrainable_params\n",
        "\n",
        "    res = {\n",
        "        \"name\": name,\n",
        "        \"history\": history.history,\n",
        "        \"n_parameters\": total_params\n",
        "    }\n",
        "\n",
        "    with open(f'drive/MyDrive/{name}_result.dict', 'wb') as f:\n",
        "        pickle.dump(res, f)"
      ],
      "id": "JyZKXVtwMimL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHRsWUhPNUnS"
      },
      "source": [
        "with open(metadata_file, \"r\") as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "models = [\n",
        "    #{\n",
        "    #    \"name\": \"VGG11\",\n",
        "    #    \"model\": initialize_vgg(2, None, (*(metadata[\"img_size\"][:2]), 3), dropout=0.01),\n",
        "    #    \"batch_size\": 128\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG14\",\n",
        "    #    \"model\": initialize_vgg(3, None, (*(metadata[\"img_size\"][:2]), 3), dropout=0.005),\n",
        "    #    \"batch_size\": 128\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG17\",\n",
        "    #    \"model\": initialize_vgg(4, None, (*(metadata[\"img_size\"][:2]), 3), dropout=0.005),\n",
        "    #    \"batch_size\": 64\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG20\",\n",
        "    #    \"model\": initialize_vgg(5, None, (*(metadata[\"img_size\"][:2]), 3), dropout=0.005),\n",
        "    #    \"batch_size\": 64\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG11-3D\",\n",
        "    #    \"model\": initialize_vgg_3d(2, None, (*(metadata[\"img_size\"][:2]), 3), seq_size=128, filter_reduction_fac=3, dropout=0.01),\n",
        "    #    \"batch_size\": 1,\n",
        "    #    \"seq_size\": 128\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG14-3D\",\n",
        "    #    \"model\": initialize_vgg_3d(3, None, (*(metadata[\"img_size\"][:2]), 3), seq_size=128, filter_reduction_fac=3, dropout=0.01),\n",
        "    #    \"batch_size\": 1,\n",
        "    #    \"seq_size\": 128\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG17-3D\",\n",
        "    #    \"model\": initialize_vgg_3d(4, None, (*(metadata[\"img_size\"][:2]), 3), seq_size=64, filter_reduction_fac=3, dropout=0.1),\n",
        "    #    \"batch_size\": 1,\n",
        "    #    \"seq_size\": 64\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG20-3D\",\n",
        "    #    \"model\": initialize_vgg_3d(5, None, (*(metadata[\"img_size\"][:2]), 3), seq_size=128, filter_reduction_fac=3, dropout=0.01),\n",
        "    #    \"batch_size\": 1,\n",
        "    #    \"seq_size\": 128\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG11-LSTM\",\n",
        "    #    \"model\": initialize_vgg_lstm(2, 64, (*(metadata[\"img_size\"][:2]), 3), seq_size=2, filter_reduction_fac=8, dropout=0.05),\n",
        "    #    \"batch_size\": 64,\n",
        "    #    \"seq_size\": 2,\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG14-LSTM\",\n",
        "    #    \"model\": initialize_vgg_lstm(3, 64, (*(metadata[\"img_size\"][:2]), 3), seq_size=2, filter_reduction_fac=8, dropout=0.001),\n",
        "    #    \"batch_size\": 64,\n",
        "    #    \"seq_size\": 2,\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG17-LSTM\",\n",
        "    #    \"model\": initialize_vgg_lstm(4, 32, (*(metadata[\"img_size\"][:2]), 3), seq_size=2, filter_reduction_fac=8, dropout=0.0001),\n",
        "    #    \"batch_size\": 32,\n",
        "    #    \"seq_size\": 2,\n",
        "    #},\n",
        "    #{\n",
        "    #    \"name\": \"VGG20-LSTM\",\n",
        "    #    \"model\": initialize_vgg_lstm(5, 32, (*(metadata[\"img_size\"][:2]), 3), seq_size=2, filter_reduction_fac=8, dropout=0.05),\n",
        "    #    \"batch_size\": 32,\n",
        "    #    \"seq_size\": 2,\n",
        "    #},\n",
        "]\n",
        "for model in models:\n",
        "    train_model(**model)"
      ],
      "id": "mHRsWUhPNUnS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAzWPcDG7fpa"
      },
      "source": [
        ""
      ],
      "id": "vAzWPcDG7fpa",
      "execution_count": null,
      "outputs": []
    }
  ]
}